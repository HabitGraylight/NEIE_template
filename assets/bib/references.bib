@inproceedings{10.1145/3583780.3615277,
author = {Gunaratna, Kalpa and Srinivasan, Vijay and Jin, Hongxia},
title = {Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615277},
doi = {10.1145/3583780.3615277},
abstract = {Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be 'inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3913–3917},
numpages = {5},
keywords = {slot filling, joint NLU, intent classification, inherent explainability},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@article{YXXY20250307001,
author = {郭蕾蕾},
title = {生成式人工智能驱动教育变革：机制、风险及应对——以DeepSeek为例},
journal = {重庆高教研究},
pages = {1-10},
issn = {1673-8012},
}    
